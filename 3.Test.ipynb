{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-20T00:43:04.467312Z",
     "start_time": "2024-06-20T00:42:30.035280Z"
    }
   },
   "source": [
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "from gosdt.model.threshold_guess import compute_thresholds, cut\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imodels.tree.gosdt.pygosdt import OptimalTreeClassifier\n",
    "import random\n",
    "import torch\n",
    "import sklearn\n",
    "from gosdt import GOSDT\n",
    "from metatree.model_metatree import LlamaForMetaTree as MetaTree\n",
    "from metatree.decision_tree_class import DecisionTree, DecisionTreeForest\n",
    "from metatree.run_train import preprocess_dimension_patch\n",
    "\n",
    "from transformers import AutoConfig\n",
    "\n",
    "model_name_or_path = \"yzhuang/MetaTree\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "model = MetaTree.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    config=config,\n",
    ")   \n",
    "decision_tree_forest = DecisionTreeForest()\n",
    "\n",
    "ensemble_size = 1\n",
    "seed = 42\n",
    "# Load the new dataset\n",
    "arff_file = arff.loadarff('./dataset/3.dataset_18_mfeat-morphological.arff')\n",
    "df = pd.DataFrame(arff_file[0])\n",
    "print(df)\n",
    "mapping = {\n",
    "    b'1': 1,\n",
    "    b'2': 2,\n",
    "    b'3': 3,\n",
    "    b'4': 4,\n",
    "    b'5': 5,\n",
    "    b'6': 6,\n",
    "    b'7': 7,\n",
    "    b'8': 8,\n",
    "    b'9': 9,\n",
    "    b'10': 10\n",
    "}\n",
    "df['Result'] = df['class'].apply(lambda x: mapping.get(x, 0))\n",
    "# print(df['class'].unique())\n",
    "\n",
    "# Drop the original binaryClass column\n",
    "df.drop(columns=['class'], inplace=True)\n",
    "print(df)\n",
    "X, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "df.info()\n",
    "df = df.astype(int)\n",
    "df.info()\n",
    "feature_names = df.columns[:-1]\n",
    "\n",
    "print(\"Dataset Shapes X={}, y={}, Num of Classes={}\".format(X.shape, y.shape, len(set(y))))\n",
    "\n",
    "train_idx, test_idx = sklearn.model_selection.train_test_split(range(X.shape[0]), test_size=0.3, random_state=seed)\n",
    "print(len(train_idx))\n",
    "\n",
    "# Dimension \n",
    "random.seed(seed)\n",
    "feature_idx = np.random.choice(X.shape[1], 6, replace=False)\n",
    "X = X.iloc[:, feature_idx]  # Updated line\n",
    "\n",
    "test_X, test_y = X.iloc[test_idx], y.iloc[test_idx]  # Updated line\n",
    "\n",
    "for i in range(ensemble_size):\n",
    "    # Sample Train and Test Data\n",
    "    random.seed(seed+i+1)\n",
    "    subset_idx = random.sample(train_idx, 256)\n",
    "    train_X, train_y = X.iloc[subset_idx], y.iloc[subset_idx]  # Updated line\n",
    "\n",
    "    input_x = torch.tensor(train_X.values, dtype=torch.float32)  # Convert DataFrame to NumPy array before tensor\n",
    "    input_y = torch.nn.functional.one_hot(torch.tensor(train_y.values, dtype= torch.long)).float()  # Convert Series to NumPy array before tensor\n",
    "\n",
    "    batch = {\"input_x\": input_x, \"input_y\": input_y, \"input_y_clean\": input_y}\n",
    "    batch = preprocess_dimension_patch(batch, n_feature=10, n_class=10)\n",
    "    model.depth = 2\n",
    "    outputs = model.generate_decision_tree(batch['input_x'], batch['input_y'], depth=model.depth)\n",
    "    decision_tree_forest.add_tree(DecisionTree(auto_dims=outputs.metatree_dimensions, auto_thresholds=outputs.tentative_splits, input_x=batch['input_x'], input_y=batch['input_y'], depth=model.depth))\n",
    "\n",
    "    print(\"Decision Tree Features: \", [x.argmax(dim=-1) for x in outputs.metatree_dimensions])\n",
    "    print(\"Decision Tree Threasholds: \", outputs.tentative_splits)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thanhnguyen/PycharmProjects/scientificProject/venv/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/thanhnguyen/PycharmProjects/scientificProject/venv/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/thanhnguyen/PycharmProjects/scientificProject/venv/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      att1  att2  att3        att4      att5         att6  class\n",
      "0      1.0   0.0   0.0  133.150861  1.311693  1620.221779   b'1'\n",
      "1      1.0   0.0   0.0  126.724861  1.302745  1609.334822   b'1'\n",
      "2      1.0   0.0   0.0  131.173861  1.319031  1568.978435   b'1'\n",
      "3      1.0   0.0   0.0  129.478861  1.270878  1695.055281   b'1'\n",
      "4      1.0   0.0   0.0  127.262861  1.329637  1647.720235   b'1'\n",
      "...    ...   ...   ...         ...       ...          ...    ...\n",
      "1995   1.0   1.0   1.0  157.498861  1.655794  5326.025889  b'10'\n",
      "1996   1.0   1.0   1.0  152.404861  1.620345  5243.267754  b'10'\n",
      "1997   1.0   1.0   1.0  134.672861  1.541987  3766.763222  b'10'\n",
      "1998   1.0   1.0   1.0  142.926861  1.426381  4118.327320  b'10'\n",
      "1999   1.0   1.0   1.0  133.920861  1.564621  3808.021317  b'10'\n",
      "\n",
      "[2000 rows x 7 columns]\n",
      "      att1  att2  att3        att4      att5         att6  Result\n",
      "0      1.0   0.0   0.0  133.150861  1.311693  1620.221779       1\n",
      "1      1.0   0.0   0.0  126.724861  1.302745  1609.334822       1\n",
      "2      1.0   0.0   0.0  131.173861  1.319031  1568.978435       1\n",
      "3      1.0   0.0   0.0  129.478861  1.270878  1695.055281       1\n",
      "4      1.0   0.0   0.0  127.262861  1.329637  1647.720235       1\n",
      "...    ...   ...   ...         ...       ...          ...     ...\n",
      "1995   1.0   1.0   1.0  157.498861  1.655794  5326.025889      10\n",
      "1996   1.0   1.0   1.0  152.404861  1.620345  5243.267754      10\n",
      "1997   1.0   1.0   1.0  134.672861  1.541987  3766.763222      10\n",
      "1998   1.0   1.0   1.0  142.926861  1.426381  4118.327320      10\n",
      "1999   1.0   1.0   1.0  133.920861  1.564621  3808.021317      10\n",
      "\n",
      "[2000 rows x 7 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   att1    2000 non-null   float64\n",
      " 1   att2    2000 non-null   float64\n",
      " 2   att3    2000 non-null   float64\n",
      " 3   att4    2000 non-null   float64\n",
      " 4   att5    2000 non-null   float64\n",
      " 5   att6    2000 non-null   float64\n",
      " 6   Result  2000 non-null   int64  \n",
      "dtypes: float64(6), int64(1)\n",
      "memory usage: 109.5 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   att1    2000 non-null   int64\n",
      " 1   att2    2000 non-null   int64\n",
      " 2   att3    2000 non-null   int64\n",
      " 3   att4    2000 non-null   int64\n",
      " 4   att5    2000 non-null   int64\n",
      " 5   att6    2000 non-null   int64\n",
      " 6   Result  2000 non-null   int64\n",
      "dtypes: int64(7)\n",
      "memory usage: 109.5 KB\n",
      "Dataset Shapes X=(2000, 6), y=(2000,), Num of Classes=10\n",
      "1400\n",
      "Decision Tree Features:  [tensor([5]), tensor([0]), tensor([5])]\n",
      "Decision Tree Threasholds:  [tensor([[0.5000]]), tensor([[1.6967]]), tensor([[0.5000]])]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:43:04.494246Z",
     "start_time": "2024-06-20T00:43:04.473086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tree_pred = decision_tree_forest.predict(torch.tensor(test_X.values, dtype=torch.float32))\n",
    "\n",
    "accuracy = accuracy_score(test_y.values, tree_pred.argmax(dim=-1).squeeze(0))\n",
    "print(\"MetaTree Test Accuracy: \", accuracy)\n"
   ],
   "id": "64e4f76726908522",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaTree Test Accuracy:  0.33666666666666667\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:43:04.530446Z",
     "start_time": "2024-06-20T00:43:04.497466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cart_ensemble = []\n",
    "\n",
    "for i in range(ensemble_size):\n",
    "    random.seed(seed + i + 1)\n",
    "    subset_idx = random.sample(train_idx, 256)\n",
    "    train_X, train_y = X.iloc[subset_idx], y.iloc[subset_idx]  # Use .iloc for row indexing\n",
    "    \n",
    "    clf = sklearn.tree.DecisionTreeClassifier(max_depth=2, random_state=seed + i + 1)\n",
    "    clf.fit(train_X.values, train_y.values)\n",
    "    cart_ensemble.append(clf)\n",
    "\n",
    "overall_pred = np.zeros((test_X.values.shape[0], len(set(test_y))))\n",
    "for clf in cart_ensemble:\n",
    "    overall_pred += clf.predict_proba(test_X.values)\n",
    "overall_pred = overall_pred / len(cart_ensemble)\n",
    "\n",
    "accuracy = accuracy_score(test_y.values, overall_pred.argmax(axis=-1))\n",
    "print(\"CART Test Accuracy: \", accuracy)\n"
   ],
   "id": "6b309dde3cc361a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART Test Accuracy:  0.09166666666666666\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:43:04.539923Z",
     "start_time": "2024-06-20T00:43:04.533613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Tiếp tục từ đoạn code của bạn\n",
    "# # Định nghĩa các tham số cho mô hình GOSDT\n",
    "# gosdt_params = {\n",
    "#     'regularization': 0.01,\n",
    "#     'time_limit': 60,  # giới hạn thời gian tính toán là 60 giây\n",
    "#     'verbose': True\n",
    "# }\n",
    "# \n",
    "# # Khởi tạo mô hình GOSDT với các tham số đã định nghĩa\n",
    "# gosdt_model = GOSDT(gosdt_params)\n",
    "# \n",
    "# # Huấn luyện mô hình GOSDT với tập dữ liệu huấn luyện\n",
    "# gosdt_model.fit(train_X, train_y)\n",
    "# \n",
    "# # Dự đoán kết quả trên tập dữ liệu kiểm tra\n",
    "# predictions = gosdt_model.predict(test_X)\n",
    "# \n",
    "# # Tính toán độ chính xác của mô hình\n",
    "# accuracy = accuracy_score(test_y, predictions)\n",
    "# print(f'Độ chính xác của mô hình GOSDT: {accuracy}')\n"
   ],
   "id": "a1bdb794674d1d93",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:43:04.550774Z",
     "start_time": "2024-06-20T00:43:04.544896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# gosdt_ensemble = []\n",
    "# \n",
    "# for i in range(ensemble_size):\n",
    "#     random.seed(seed + i + 1)\n",
    "#     subset_idx = random.sample(train_idx, 256)\n",
    "#     train_X, train_y = X.iloc[subset_idx], y.iloc[subset_idx]  # Use .iloc for row indexing\n",
    "#     glf = OptimalTreeClassifier(random_state=seed + i + 1)\n",
    "#     print(glf.max_depth())\n",
    "#     gosdt_ensemble.append(predictions)\n",
    "# overall_pred_gosdt = np.zeros((test_X.values.shape[0], len(set(test_y))))\n",
    "# for glf in gosdt_ensemble:\n",
    "#     overall_pred_gosdt += glf.predict_proba(test_X.values)\n",
    "# overall_pred_gosdt = overall_pred_gosdt / len(gosdt_ensemble)\n",
    "# \n",
    "# accuracy = accuracy_score(test_y.values, overall_pred_gosdt.argmax(axis=-1))\n",
    "# print(\"GOSDT Test Accuracy: \", accuracy)\n",
    "#     "
   ],
   "id": "d056f1621dfb56bb",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:43:04.557535Z",
     "start_time": "2024-06-20T00:43:04.553692Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "213b7c82685c8e8f",
   "outputs": [],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
