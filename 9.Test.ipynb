{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-20T00:54:24.055188Z",
     "start_time": "2024-06-20T00:53:56.189087Z"
    }
   },
   "source": [
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "from gosdt.model.threshold_guess import compute_thresholds, cut\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imodels.tree.gosdt.pygosdt import OptimalTreeClassifier\n",
    "import random\n",
    "import torch\n",
    "import sklearn\n",
    "from gosdt import GOSDT\n",
    "from metatree.model_metatree import LlamaForMetaTree as MetaTree\n",
    "from metatree.decision_tree_class import DecisionTree, DecisionTreeForest\n",
    "from metatree.run_train import preprocess_dimension_patch\n",
    "\n",
    "from transformers import AutoConfig\n",
    "\n",
    "model_name_or_path = \"yzhuang/MetaTree\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "model = MetaTree.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    config=config,\n",
    ")   \n",
    "decision_tree_forest = DecisionTreeForest()\n",
    "\n",
    "ensemble_size = 1\n",
    "seed = 42\n",
    "# Load the new dataset\n",
    "arff_file = arff.loadarff('./dataset/9.pokerhand.arff')\n",
    "df = pd.DataFrame(arff_file[0])\n",
    "print(df)\n",
    "mapping = {\n",
    "    b'0': 0,\n",
    "    b'1': 1,\n",
    "    b'2': 2,\n",
    "    b'3': 3,\n",
    "    b'4': 4,\n",
    "    b'5': 5,\n",
    "    b'6': 6,\n",
    "    b'7': 7,\n",
    "    b'8': 8,\n",
    "    b'9': 9,\n",
    "    b'10': 10\n",
    "}\n",
    "df['Result'] = df['class'].apply(lambda x: mapping.get(x, 0))\n",
    "# print(df['class'].unique())\n",
    "\n",
    "# Drop the original binaryClass column\n",
    "df.drop(columns=['class'], inplace=True)\n",
    "print(df)\n",
    "X, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "df.info()\n",
    "df = df.astype(int)\n",
    "df.info()\n",
    "feature_names = df.columns[:-1]\n",
    "\n",
    "print(\"Dataset Shapes X={}, y={}, Num of Classes={}\".format(X.shape, y.shape, len(set(y))))\n",
    "\n",
    "train_idx, test_idx = sklearn.model_selection.train_test_split(range(X.shape[0]), test_size=0.3, random_state=seed)\n",
    "print(len(train_idx))\n",
    "\n",
    "# Dimension \n",
    "random.seed(seed)\n",
    "feature_idx = np.random.choice(X.shape[1], 10, replace=False)\n",
    "X = X.iloc[:, feature_idx]  # Updated line\n",
    "\n",
    "test_X, test_y = X.iloc[test_idx], y.iloc[test_idx]  # Updated line\n",
    "\n",
    "for i in range(ensemble_size):\n",
    "    # Sample Train and Test Data\n",
    "    random.seed(seed+i+1)\n",
    "    subset_idx = random.sample(train_idx, 256)\n",
    "    train_X, train_y = X.iloc[subset_idx], y.iloc[subset_idx]  # Updated line\n",
    "\n",
    "    input_x = torch.tensor(train_X.values, dtype=torch.float32)  # Convert DataFrame to NumPy array before tensor\n",
    "    input_y = torch.nn.functional.one_hot(torch.tensor(train_y.values, dtype= torch.long)).float()  # Convert Series to NumPy array before tensor\n",
    "\n",
    "    batch = {\"input_x\": input_x, \"input_y\": input_y, \"input_y_clean\": input_y}\n",
    "    batch = preprocess_dimension_patch(batch, n_feature=10, n_class=10)\n",
    "    model.depth = 2\n",
    "    outputs = model.generate_decision_tree(batch['input_x'], batch['input_y'], depth=model.depth)\n",
    "    decision_tree_forest.add_tree(DecisionTree(auto_dims=outputs.metatree_dimensions, auto_thresholds=outputs.tentative_splits, input_x=batch['input_x'], input_y=batch['input_y'], depth=model.depth))\n",
    "\n",
    "    print(\"Decision Tree Features: \", [x.argmax(dim=-1) for x in outputs.metatree_dimensions])\n",
    "    print(\"Decision Tree Threasholds: \", outputs.tentative_splits)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thanhnguyen/PycharmProjects/scientificProject/venv/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/thanhnguyen/PycharmProjects/scientificProject/venv/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/thanhnguyen/PycharmProjects/scientificProject/venv/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          s1   r1    s2    r2    s3    r3    s4    r4    s5    r5 class\n",
      "0       b'1'  1.0  b'1'  10.0  b'1'  11.0  b'1'  12.0  b'2'  13.0  b'4'\n",
      "1       b'1'  1.0  b'1'  10.0  b'1'  11.0  b'1'  12.0  b'4'  13.0  b'4'\n",
      "2       b'1'  1.0  b'1'  10.0  b'1'  11.0  b'2'  11.0  b'1'  12.0  b'1'\n",
      "3       b'1'  1.0  b'1'  10.0  b'1'  11.0  b'2'  11.0  b'1'  13.0  b'1'\n",
      "4       b'1'  1.0  b'1'  10.0  b'1'  11.0  b'2'  11.0  b'2'  12.0  b'1'\n",
      "...      ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...\n",
      "829196  b'4'  9.0  b'4'  11.0  b'3'  12.0  b'4'  12.0  b'1'  13.0  b'1'\n",
      "829197  b'4'  9.0  b'4'  11.0  b'3'  12.0  b'4'  12.0  b'3'  13.0  b'1'\n",
      "829198  b'4'  9.0  b'4'  11.0  b'3'  12.0  b'4'  12.0  b'4'  13.0  b'1'\n",
      "829199  b'4'  9.0  b'4'  11.0  b'4'  12.0  b'1'  13.0  b'2'  13.0  b'1'\n",
      "829200  b'4'  9.0  b'4'  12.0  b'2'  13.0  b'3'  13.0  b'4'  13.0  b'3'\n",
      "\n",
      "[829201 rows x 11 columns]\n",
      "          s1   r1    s2    r2    s3    r3    s4    r4    s5    r5  Result\n",
      "0       b'1'  1.0  b'1'  10.0  b'1'  11.0  b'1'  12.0  b'2'  13.0       4\n",
      "1       b'1'  1.0  b'1'  10.0  b'1'  11.0  b'1'  12.0  b'4'  13.0       4\n",
      "2       b'1'  1.0  b'1'  10.0  b'1'  11.0  b'2'  11.0  b'1'  12.0       1\n",
      "3       b'1'  1.0  b'1'  10.0  b'1'  11.0  b'2'  11.0  b'1'  13.0       1\n",
      "4       b'1'  1.0  b'1'  10.0  b'1'  11.0  b'2'  11.0  b'2'  12.0       1\n",
      "...      ...  ...   ...   ...   ...   ...   ...   ...   ...   ...     ...\n",
      "829196  b'4'  9.0  b'4'  11.0  b'3'  12.0  b'4'  12.0  b'1'  13.0       1\n",
      "829197  b'4'  9.0  b'4'  11.0  b'3'  12.0  b'4'  12.0  b'3'  13.0       1\n",
      "829198  b'4'  9.0  b'4'  11.0  b'3'  12.0  b'4'  12.0  b'4'  13.0       1\n",
      "829199  b'4'  9.0  b'4'  11.0  b'4'  12.0  b'1'  13.0  b'2'  13.0       1\n",
      "829200  b'4'  9.0  b'4'  12.0  b'2'  13.0  b'3'  13.0  b'4'  13.0       3\n",
      "\n",
      "[829201 rows x 11 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 829201 entries, 0 to 829200\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   s1      829201 non-null  object \n",
      " 1   r1      829201 non-null  float64\n",
      " 2   s2      829201 non-null  object \n",
      " 3   r2      829201 non-null  float64\n",
      " 4   s3      829201 non-null  object \n",
      " 5   r3      829201 non-null  float64\n",
      " 6   s4      829201 non-null  object \n",
      " 7   r4      829201 non-null  float64\n",
      " 8   s5      829201 non-null  object \n",
      " 9   r5      829201 non-null  float64\n",
      " 10  Result  829201 non-null  int64  \n",
      "dtypes: float64(5), int64(1), object(5)\n",
      "memory usage: 69.6+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 829201 entries, 0 to 829200\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count   Dtype\n",
      "---  ------  --------------   -----\n",
      " 0   s1      829201 non-null  int64\n",
      " 1   r1      829201 non-null  int64\n",
      " 2   s2      829201 non-null  int64\n",
      " 3   r2      829201 non-null  int64\n",
      " 4   s3      829201 non-null  int64\n",
      " 5   r3      829201 non-null  int64\n",
      " 6   s4      829201 non-null  int64\n",
      " 7   r4      829201 non-null  int64\n",
      " 8   s5      829201 non-null  int64\n",
      " 9   r5      829201 non-null  int64\n",
      " 10  Result  829201 non-null  int64\n",
      "dtypes: int64(11)\n",
      "memory usage: 69.6 MB\n",
      "Dataset Shapes X=(829201, 10), y=(829201,), Num of Classes=10\n",
      "580440\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 80\u001B[0m\n\u001B[1;32m     77\u001B[0m subset_idx \u001B[38;5;241m=\u001B[39m random\u001B[38;5;241m.\u001B[39msample(train_idx, \u001B[38;5;241m256\u001B[39m)\n\u001B[1;32m     78\u001B[0m train_X, train_y \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39miloc[subset_idx], y\u001B[38;5;241m.\u001B[39miloc[subset_idx]  \u001B[38;5;66;03m# Updated line\u001B[39;00m\n\u001B[0;32m---> 80\u001B[0m input_x \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_X\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Convert DataFrame to NumPy array before tensor\u001B[39;00m\n\u001B[1;32m     81\u001B[0m input_y \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mone_hot(torch\u001B[38;5;241m.\u001B[39mtensor(train_y\u001B[38;5;241m.\u001B[39mvalues, dtype\u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlong))\u001B[38;5;241m.\u001B[39mfloat()  \u001B[38;5;66;03m# Convert Series to NumPy array before tensor\u001B[39;00m\n\u001B[1;32m     83\u001B[0m batch \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_x\u001B[39m\u001B[38;5;124m\"\u001B[39m: input_x, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_y\u001B[39m\u001B[38;5;124m\"\u001B[39m: input_y, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_y_clean\u001B[39m\u001B[38;5;124m\"\u001B[39m: input_y}\n",
      "\u001B[0;31mTypeError\u001B[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool."
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T00:54:24.057819Z",
     "start_time": "2024-06-20T00:54:24.057463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tree_pred = decision_tree_forest.predict(torch.tensor(test_X.values, dtype=torch.float32))\n",
    "\n",
    "accuracy = accuracy_score(test_y.values, tree_pred.argmax(dim=-1).squeeze(0))\n",
    "print(\"MetaTree Test Accuracy: \", accuracy)\n"
   ],
   "id": "64e4f76726908522",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cart_ensemble = []\n",
    "\n",
    "for i in range(ensemble_size):\n",
    "    random.seed(seed + i + 1)\n",
    "    subset_idx = random.sample(train_idx, 256)\n",
    "    train_X, train_y = X.iloc[subset_idx], y.iloc[subset_idx]  # Use .iloc for row indexing\n",
    "    \n",
    "    clf = sklearn.tree.DecisionTreeClassifier(max_depth=2, random_state=seed + i + 1)\n",
    "    clf.fit(train_X.values, train_y.values)\n",
    "    cart_ensemble.append(clf)\n",
    "\n",
    "overall_pred = np.zeros((test_X.values.shape[0], len(set(test_y))))\n",
    "for clf in cart_ensemble:\n",
    "    overall_pred += clf.predict_proba(test_X.values)\n",
    "overall_pred = overall_pred / len(cart_ensemble)\n",
    "\n",
    "accuracy = accuracy_score(test_y.values, overall_pred.argmax(axis=-1))\n",
    "print(\"CART Test Accuracy: \", accuracy)\n"
   ],
   "id": "6b309dde3cc361a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Tiếp tục từ đoạn code của bạn\n",
    "# # Định nghĩa các tham số cho mô hình GOSDT\n",
    "# gosdt_params = {\n",
    "#     'regularization': 0.01,\n",
    "#     'time_limit': 60,  # giới hạn thời gian tính toán là 60 giây\n",
    "#     'verbose': True\n",
    "# }\n",
    "# \n",
    "# # Khởi tạo mô hình GOSDT với các tham số đã định nghĩa\n",
    "# gosdt_model = GOSDT(gosdt_params)\n",
    "# \n",
    "# # Huấn luyện mô hình GOSDT với tập dữ liệu huấn luyện\n",
    "# gosdt_model.fit(train_X, train_y)\n",
    "# \n",
    "# # Dự đoán kết quả trên tập dữ liệu kiểm tra\n",
    "# predictions = gosdt_model.predict(test_X)\n",
    "# \n",
    "# # Tính toán độ chính xác của mô hình\n",
    "# accuracy = accuracy_score(test_y, predictions)\n",
    "# print(f'Độ chính xác của mô hình GOSDT: {accuracy}')\n"
   ],
   "id": "a1bdb794674d1d93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# gosdt_ensemble = []\n",
    "# \n",
    "# for i in range(ensemble_size):\n",
    "#     random.seed(seed + i + 1)\n",
    "#     subset_idx = random.sample(train_idx, 256)\n",
    "#     train_X, train_y = X.iloc[subset_idx], y.iloc[subset_idx]  # Use .iloc for row indexing\n",
    "#     glf = OptimalTreeClassifier(random_state=seed + i + 1)\n",
    "#     print(glf.max_depth())\n",
    "#     gosdt_ensemble.append(predictions)\n",
    "# overall_pred_gosdt = np.zeros((test_X.values.shape[0], len(set(test_y))))\n",
    "# for glf in gosdt_ensemble:\n",
    "#     overall_pred_gosdt += glf.predict_proba(test_X.values)\n",
    "# overall_pred_gosdt = overall_pred_gosdt / len(gosdt_ensemble)\n",
    "# \n",
    "# accuracy = accuracy_score(test_y.values, overall_pred_gosdt.argmax(axis=-1))\n",
    "# print(\"GOSDT Test Accuracy: \", accuracy)\n",
    "#     "
   ],
   "id": "d056f1621dfb56bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "213b7c82685c8e8f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
